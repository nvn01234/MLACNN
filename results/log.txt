load data
load embeddings
training
log_dir = log/1524912024
training fold 1
Train on 1371 samples, validate on 345 samples
Epoch 1/100
 - 3s - loss: 3.6392 - acc: 0.4683 - val_loss: 3.0209 - val_acc: 0.4261
 - f1: 0.47

Epoch 00001: f1 improved from -inf to 0.47232, saving model to log/1524912024/1524912024/weights_1.best.h5
Epoch 2/100
 - 3s - loss: 2.2343 - acc: 0.6295 - val_loss: 0.9533 - val_acc: 0.7942
 - f1: 0.86

Epoch 00002: f1 improved from 0.47232 to 0.86319, saving model to log/1524912024/1524912024/weights_1.best.h5
Epoch 3/100
 - 3s - loss: 1.7827 - acc: 0.6878 - val_loss: 2.8712 - val_acc: 0.5333
 - f1: 0.47

Epoch 00003: f1 did not improve
Epoch 4/100
 - 3s - loss: 1.4978 - acc: 0.7177 - val_loss: 0.6959 - val_acc: 0.8348
 - f1: 0.89

Epoch 00004: f1 improved from 0.86319 to 0.88965, saving model to log/1524912024/1524912024/weights_1.best.h5
Epoch 5/100
 - 3s - loss: 1.3697 - acc: 0.7265 - val_loss: 0.5641 - val_acc: 0.8029
 - f1: 0.85

Epoch 00005: f1 did not improve
Epoch 6/100
 - 3s - loss: 1.3377 - acc: 0.7228 - val_loss: 0.5030 - val_acc: 0.8406
 - f1: 0.89

Epoch 00006: f1 did not improve
Epoch 7/100
 - 3s - loss: 1.2695 - acc: 0.7236 - val_loss: 0.5100 - val_acc: 0.8058
 - f1: 0.86

Epoch 00007: f1 did not improve
Epoch 8/100
 - 3s - loss: 1.0823 - acc: 0.7491 - val_loss: 0.5822 - val_acc: 0.8522
 - f1: 0.90

Epoch 00008: f1 improved from 0.88965 to 0.90374, saving model to log/1524912024/1524912024/weights_1.best.h5
Epoch 9/100
 - 3s - loss: 1.0365 - acc: 0.7505 - val_loss: 2.3407 - val_acc: 0.4899
 - f1: 0.56

Epoch 00009: f1 did not improve
Epoch 10/100
 - 3s - loss: 0.9750 - acc: 0.7695 - val_loss: 7.6260 - val_acc: 0.3594
 - f1: 0.38

Epoch 00010: f1 did not improve
Epoch 11/100
 - 3s - loss: 1.4980 - acc: 0.7396 - val_loss: 0.8655 - val_acc: 0.7594
 - f1: 0.84

Epoch 00011: f1 did not improve
Epoch 12/100
 - 3s - loss: 1.0457 - acc: 0.7629 - val_loss: 1.8051 - val_acc: 0.7188
 - f1: 0.71

Epoch 00012: f1 did not improve
Epoch 13/100
 - 3s - loss: 0.8990 - acc: 0.7877 - val_loss: 1.2017 - val_acc: 0.7913
 - f1: 0.80

Epoch 00013: f1 did not improve
testing fold 1
f1_score: 0.90
training fold 2
Train on 1372 samples, validate on 344 samples
Epoch 1/100
 - 3s - loss: 3.3591 - acc: 0.4657 - val_loss: 2.5867 - val_acc: 0.7209
 - f1: 0.80

Epoch 00001: f1 improved from -inf to 0.80019, saving model to log/1524912024/1524912024/weights_2.best.h5
Epoch 2/100
 - 3s - loss: 2.0334 - acc: 0.6246 - val_loss: 0.6202 - val_acc: 0.8052
 - f1: 0.86

Epoch 00002: f1 improved from 0.80019 to 0.85897, saving model to log/1524912024/1524912024/weights_2.best.h5
Epoch 3/100
 - 3s - loss: 1.6451 - acc: 0.6691 - val_loss: 0.6945 - val_acc: 0.8198
 - f1: 0.88

Epoch 00003: f1 improved from 0.85897 to 0.87881, saving model to log/1524912024/1524912024/weights_2.best.h5
Epoch 4/100
 - 3s - loss: 1.4966 - acc: 0.7041 - val_loss: 1.6070 - val_acc: 0.7936
 - f1: 0.87

Epoch 00004: f1 did not improve
Epoch 5/100
 - 3s - loss: 1.2796 - acc: 0.7332 - val_loss: 1.6974 - val_acc: 0.7442
 - f1: 0.80

Epoch 00005: f1 did not improve
Epoch 6/100
 - 3s - loss: 1.2277 - acc: 0.7310 - val_loss: 0.6056 - val_acc: 0.8372
 - f1: 0.89

Epoch 00006: f1 improved from 0.87881 to 0.88943, saving model to log/1524912024/1524912024/weights_2.best.h5
Epoch 7/100
 - 3s - loss: 1.0476 - acc: 0.7515 - val_loss: 0.6588 - val_acc: 0.8256
 - f1: 0.88

Epoch 00007: f1 did not improve
Epoch 8/100
 - 3s - loss: 1.0931 - acc: 0.7405 - val_loss: 0.6998 - val_acc: 0.7820
 - f1: 0.82

Epoch 00008: f1 did not improve
Epoch 9/100
 - 3s - loss: 0.9320 - acc: 0.7595 - val_loss: 0.7895 - val_acc: 0.7994
 - f1: 0.88

Epoch 00009: f1 did not improve
Epoch 10/100
 - 3s - loss: 0.9958 - acc: 0.7464 - val_loss: 0.4434 - val_acc: 0.8343
 - f1: 0.88

Epoch 00010: f1 did not improve
Epoch 11/100
 - 3s - loss: 0.7992 - acc: 0.7959 - val_loss: 1.0710 - val_acc: 0.7703
 - f1: 0.85

Epoch 00011: f1 did not improve
testing fold 2
f1_score: 0.89
training fold 3
Train on 1373 samples, validate on 343 samples
Epoch 1/100
 - 3s - loss: 3.6823 - acc: 0.4603 - val_loss: 1.2360 - val_acc: 0.7609
 - f1: 0.84

Epoch 00001: f1 improved from -inf to 0.84317, saving model to log/1524912024/1524912024/weights_3.best.h5
Epoch 2/100
 - 3s - loss: 2.1249 - acc: 0.6184 - val_loss: 1.3383 - val_acc: 0.7813
 - f1: 0.86

Epoch 00002: f1 improved from 0.84317 to 0.85814, saving model to log/1524912024/1524912024/weights_3.best.h5
Epoch 3/100
 - 3s - loss: 1.6959 - acc: 0.6795 - val_loss: 0.6662 - val_acc: 0.8105
 - f1: 0.85

Epoch 00003: f1 did not improve
Epoch 4/100
 - 3s - loss: 1.4069 - acc: 0.7036 - val_loss: 0.4491 - val_acc: 0.8571
 - f1: 0.90

Epoch 00004: f1 improved from 0.85814 to 0.90205, saving model to log/1524912024/1524912024/weights_3.best.h5
Epoch 5/100
 - 3s - loss: 1.3625 - acc: 0.6985 - val_loss: 0.4165 - val_acc: 0.8542
 - f1: 0.90

Epoch 00005: f1 did not improve
Epoch 6/100
 - 3s - loss: 1.1916 - acc: 0.7305 - val_loss: 0.4512 - val_acc: 0.8251
 - f1: 0.87

Epoch 00006: f1 did not improve
Epoch 7/100
 - 3s - loss: 1.1951 - acc: 0.7312 - val_loss: 0.9736 - val_acc: 0.7930
 - f1: 0.86

Epoch 00007: f1 did not improve
Epoch 8/100
 - 3s - loss: 1.1182 - acc: 0.7473 - val_loss: 0.4295 - val_acc: 0.8484
 - f1: 0.90

Epoch 00008: f1 improved from 0.90205 to 0.90349, saving model to log/1524912024/1524912024/weights_3.best.h5
Epoch 9/100
 - 3s - loss: 1.0191 - acc: 0.7567 - val_loss: 0.8478 - val_acc: 0.7930
 - f1: 0.82

Epoch 00009: f1 did not improve
Epoch 10/100
 - 3s - loss: 1.0521 - acc: 0.7567 - val_loss: 0.9672 - val_acc: 0.8251
 - f1: 0.89

Epoch 00010: f1 did not improve
Epoch 11/100
 - 3s - loss: 0.9787 - acc: 0.7524 - val_loss: 0.3863 - val_acc: 0.8863
 - f1: 0.93

Epoch 00011: f1 improved from 0.90349 to 0.92708, saving model to log/1524912024/1524912024/weights_3.best.h5
Epoch 12/100
 - 3s - loss: 0.9110 - acc: 0.7582 - val_loss: 1.1084 - val_acc: 0.7609
 - f1: 0.77

Epoch 00012: f1 did not improve
Epoch 13/100
 - 3s - loss: 0.8829 - acc: 0.7575 - val_loss: 0.7287 - val_acc: 0.7668
 - f1: 0.76

Epoch 00013: f1 did not improve
Epoch 14/100
 - 3s - loss: 0.8622 - acc: 0.7866 - val_loss: 0.3644 - val_acc: 0.8630
 - f1: 0.91

Epoch 00014: f1 did not improve
Epoch 15/100
 - 3s - loss: 0.8224 - acc: 0.7866 - val_loss: 0.4248 - val_acc: 0.8455
 - f1: 0.89

Epoch 00015: f1 did not improve
Epoch 16/100
 - 3s - loss: 0.6745 - acc: 0.8179 - val_loss: 0.6050 - val_acc: 0.8367
 - f1: 0.87

Epoch 00016: f1 did not improve
testing fold 3
f1_score: 0.93
training fold 4
Train on 1374 samples, validate on 342 samples
Epoch 1/100
 - 3s - loss: 3.8477 - acc: 0.4396 - val_loss: 2.9442 - val_acc: 0.5292
 - f1: 0.45

Epoch 00001: f1 improved from -inf to 0.45298, saving model to log/1524912024/1524912024/weights_4.best.h5
Epoch 2/100
 - 3s - loss: 2.1385 - acc: 0.6303 - val_loss: 0.7532 - val_acc: 0.7924
 - f1: 0.87

Epoch 00002: f1 improved from 0.45298 to 0.86706, saving model to log/1524912024/1524912024/weights_4.best.h5
Epoch 3/100
 - 3s - loss: 1.6430 - acc: 0.6805 - val_loss: 0.5535 - val_acc: 0.8216
 - f1: 0.86

Epoch 00003: f1 did not improve
Epoch 4/100
 - 3s - loss: 1.5688 - acc: 0.7125 - val_loss: 0.5680 - val_acc: 0.8246
 - f1: 0.88

Epoch 00004: f1 improved from 0.86706 to 0.87506, saving model to log/1524912024/1524912024/weights_4.best.h5
Epoch 5/100
 - 3s - loss: 1.2773 - acc: 0.7263 - val_loss: 0.8865 - val_acc: 0.7953
 - f1: 0.87

Epoch 00005: f1 did not improve
Epoch 6/100
 - 3s - loss: 1.3080 - acc: 0.7176 - val_loss: 0.9421 - val_acc: 0.7807
 - f1: 0.80

Epoch 00006: f1 did not improve
Epoch 7/100
 - 3s - loss: 1.2090 - acc: 0.7278 - val_loss: 0.4608 - val_acc: 0.8363
 - f1: 0.87

Epoch 00007: f1 did not improve
Epoch 8/100
 - 3s - loss: 1.0383 - acc: 0.7489 - val_loss: 0.3897 - val_acc: 0.8684
 - f1: 0.90

Epoch 00008: f1 improved from 0.87506 to 0.89935, saving model to log/1524912024/1524912024/weights_4.best.h5
Epoch 9/100
 - 3s - loss: 0.9587 - acc: 0.7475 - val_loss: 0.4330 - val_acc: 0.8480
 - f1: 0.87

Epoch 00009: f1 did not improve
Epoch 10/100
 - 3s - loss: 0.9533 - acc: 0.7671 - val_loss: 0.4533 - val_acc: 0.8509
 - f1: 0.87

Epoch 00010: f1 did not improve
Epoch 11/100
 - 3s - loss: 0.9555 - acc: 0.7598 - val_loss: 0.8442 - val_acc: 0.8129
 - f1: 0.88

Epoch 00011: f1 did not improve
Epoch 12/100
 - 3s - loss: 0.8435 - acc: 0.7656 - val_loss: 0.4660 - val_acc: 0.8333
 - f1: 0.85

Epoch 00012: f1 did not improve
Epoch 13/100
 - 3s - loss: 0.8629 - acc: 0.7584 - val_loss: 0.4423 - val_acc: 0.8596
 - f1: 0.89

Epoch 00013: f1 did not improve
testing fold 4
f1_score: 0.90
training fold 5
Train on 1374 samples, validate on 342 samples
Epoch 1/100
 - 3s - loss: 3.3073 - acc: 0.4723 - val_loss: 0.9722 - val_acc: 0.7895
 - f1: 0.87

Epoch 00001: f1 improved from -inf to 0.87103, saving model to log/1524912024/1524912024/weights_5.best.h5
Epoch 2/100
 - 3s - loss: 2.1618 - acc: 0.6092 - val_loss: 1.3272 - val_acc: 0.7690
 - f1: 0.86

Epoch 00002: f1 did not improve
Epoch 3/100
 - 3s - loss: 1.6070 - acc: 0.6841 - val_loss: 0.7660 - val_acc: 0.8333
 - f1: 0.89

Epoch 00003: f1 improved from 0.87103 to 0.89256, saving model to log/1524912024/1524912024/weights_5.best.h5
Epoch 4/100
 - 3s - loss: 1.7335 - acc: 0.6841 - val_loss: 1.6017 - val_acc: 0.7895
 - f1: 0.87

Epoch 00004: f1 did not improve
Epoch 5/100
 - 3s - loss: 1.4611 - acc: 0.7089 - val_loss: 0.6840 - val_acc: 0.8012
 - f1: 0.84

Epoch 00005: f1 did not improve
Epoch 6/100
 - 3s - loss: 1.1706 - acc: 0.7336 - val_loss: 0.5984 - val_acc: 0.8187
 - f1: 0.88

Epoch 00006: f1 did not improve
Epoch 7/100
 - 3s - loss: 1.3715 - acc: 0.7220 - val_loss: 0.6469 - val_acc: 0.8392
 - f1: 0.90

Epoch 00007: f1 improved from 0.89256 to 0.89653, saving model to log/1524912024/1524912024/weights_5.best.h5
Epoch 8/100
 - 3s - loss: 1.1777 - acc: 0.7416 - val_loss: 0.4711 - val_acc: 0.8421
 - f1: 0.85

Epoch 00008: f1 did not improve
Epoch 9/100
 - 3s - loss: 1.0244 - acc: 0.7511 - val_loss: 0.3763 - val_acc: 0.8567
 - f1: 0.90

Epoch 00009: f1 improved from 0.89653 to 0.90237, saving model to log/1524912024/1524912024/weights_5.best.h5
Epoch 10/100
 - 3s - loss: 0.9528 - acc: 0.7671 - val_loss: 0.5870 - val_acc: 0.8363
 - f1: 0.89

Epoch 00010: f1 did not improve
Epoch 11/100
 - 3s - loss: 0.8803 - acc: 0.7773 - val_loss: 0.3407 - val_acc: 0.8830
 - f1: 0.91

Epoch 00011: f1 improved from 0.90237 to 0.91221, saving model to log/1524912024/1524912024/weights_5.best.h5
Epoch 12/100
 - 3s - loss: 0.8843 - acc: 0.7707 - val_loss: 0.3865 - val_acc: 0.8626
 - f1: 0.89

Epoch 00012: f1 did not improve
Epoch 13/100
 - 3s - loss: 0.8342 - acc: 0.7817 - val_loss: 0.3566 - val_acc: 0.8801
 - f1: 0.92

Epoch 00013: f1 improved from 0.91221 to 0.91878, saving model to log/1524912024/1524912024/weights_5.best.h5
Epoch 14/100
 - 3s - loss: 0.7858 - acc: 0.7926 - val_loss: 0.4203 - val_acc: 0.8450
 - f1: 0.90

Epoch 00014: f1 did not improve
Epoch 15/100
 - 3s - loss: 0.7657 - acc: 0.7686 - val_loss: 0.3385 - val_acc: 0.8830
 - f1: 0.92

Epoch 00015: f1 did not improve
Epoch 16/100
 - 3s - loss: 0.7815 - acc: 0.7758 - val_loss: 0.3821 - val_acc: 0.8655
 - f1: 0.89

Epoch 00016: f1 did not improve
Epoch 17/100
 - 3s - loss: 0.6950 - acc: 0.7875 - val_loss: 0.3778 - val_acc: 0.8596
 - f1: 0.90

Epoch 00017: f1 did not improve
Epoch 18/100
 - 3s - loss: 0.6934 - acc: 0.7984 - val_loss: 0.6208 - val_acc: 0.8363
 - f1: 0.90

Epoch 00018: f1 did not improve
testing fold 5
f1_score: 0.92
model_config: {}, f1_avg = 0.91
training fold 1
Train on 1371 samples, validate on 345 samples
Epoch 1/100
 - 3s - loss: 2.9282 - acc: 0.6368 - val_loss: 3.1452 - val_acc: 0.5043
 - f1: 0.59

Epoch 00001: f1 improved from -inf to 0.59240, saving model to log/1524912024/1524912273/weights_1.best.h5
Epoch 2/100
 - 3s - loss: 1.8430 - acc: 0.7790 - val_loss: 1.0812 - val_acc: 0.8493
 - f1: 0.90

Epoch 00002: f1 improved from 0.59240 to 0.90071, saving model to log/1524912024/1524912273/weights_1.best.h5
Epoch 3/100
 - 3s - loss: 1.4436 - acc: 0.8213 - val_loss: 1.2419 - val_acc: 0.8406
 - f1: 0.90

Epoch 00003: f1 did not improve
Epoch 4/100
 - 3s - loss: 1.3490 - acc: 0.8322 - val_loss: 1.0800 - val_acc: 0.8522
 - f1: 0.91

Epoch 00004: f1 improved from 0.90071 to 0.90792, saving model to log/1524912024/1524912273/weights_1.best.h5
Epoch 5/100
 - 3s - loss: 1.1498 - acc: 0.8432 - val_loss: 4.4798 - val_acc: 0.5043
 - f1: 0.51

Epoch 00005: f1 did not improve
Epoch 6/100
 - 3s - loss: 1.1868 - acc: 0.8359 - val_loss: 0.9008 - val_acc: 0.8783
 - f1: 0.92

Epoch 00006: f1 improved from 0.90792 to 0.92019, saving model to log/1524912024/1524912273/weights_1.best.h5
Epoch 7/100
 - 3s - loss: 1.0883 - acc: 0.8541 - val_loss: 0.8050 - val_acc: 0.9043
 - f1: 0.93

Epoch 00007: f1 improved from 0.92019 to 0.93433, saving model to log/1524912024/1524912273/weights_1.best.h5
Epoch 8/100
 - 3s - loss: 0.8983 - acc: 0.8556 - val_loss: 0.7431 - val_acc: 0.8986
 - f1: 0.93

Epoch 00008: f1 did not improve
Epoch 9/100
 - 3s - loss: 0.9109 - acc: 0.8724 - val_loss: 0.7448 - val_acc: 0.8957
 - f1: 0.93

Epoch 00009: f1 did not improve
Epoch 10/100
 - 3s - loss: 0.8233 - acc: 0.8731 - val_loss: 0.7287 - val_acc: 0.8870
 - f1: 0.92

Epoch 00010: f1 did not improve
Epoch 11/100
 - 3s - loss: 0.7651 - acc: 0.8826 - val_loss: 0.6925 - val_acc: 0.9043
 - f1: 0.93

Epoch 00011: f1 did not improve
Epoch 12/100
 - 3s - loss: 0.7778 - acc: 0.8789 - val_loss: 0.7819 - val_acc: 0.8812
 - f1: 0.91

Epoch 00012: f1 did not improve
testing fold 1
f1_score: 0.93
training fold 2
Train on 1372 samples, validate on 344 samples
Epoch 1/100
 - 4s - loss: 2.8590 - acc: 0.6443 - val_loss: 3.6511 - val_acc: 0.6221
 - f1: 0.69

Epoch 00001: f1 improved from -inf to 0.69046, saving model to log/1524912024/1524912273/weights_2.best.h5
Epoch 2/100
 - 3s - loss: 1.7247 - acc: 0.7813 - val_loss: 3.2652 - val_acc: 0.5698
 - f1: 0.64

Epoch 00002: f1 did not improve
Epoch 3/100
 - 3s - loss: 1.3702 - acc: 0.8039 - val_loss: 0.9444 - val_acc: 0.8605
 - f1: 0.90

Epoch 00003: f1 improved from 0.69046 to 0.90092, saving model to log/1524912024/1524912273/weights_2.best.h5
Epoch 4/100
 - 3s - loss: 1.2456 - acc: 0.8360 - val_loss: 0.7773 - val_acc: 0.8837
 - f1: 0.93

Epoch 00004: f1 improved from 0.90092 to 0.92594, saving model to log/1524912024/1524912273/weights_2.best.h5
Epoch 5/100
 - 3s - loss: 1.1696 - acc: 0.8397 - val_loss: 0.7799 - val_acc: 0.8895
 - f1: 0.93

Epoch 00005: f1 improved from 0.92594 to 0.92791, saving model to log/1524912024/1524912273/weights_2.best.h5
Epoch 6/100
 - 3s - loss: 1.0415 - acc: 0.8477 - val_loss: 0.7337 - val_acc: 0.9012
 - f1: 0.94

Epoch 00006: f1 improved from 0.92791 to 0.94044, saving model to log/1524912024/1524912273/weights_2.best.h5
Epoch 7/100
 - 3s - loss: 1.0053 - acc: 0.8513 - val_loss: 0.8004 - val_acc: 0.8953
 - f1: 0.94

Epoch 00007: f1 did not improve
Epoch 8/100
 - 3s - loss: 0.9633 - acc: 0.8622 - val_loss: 0.7472 - val_acc: 0.8866
 - f1: 0.93

Epoch 00008: f1 did not improve
Epoch 9/100
 - 3s - loss: 0.8947 - acc: 0.8659 - val_loss: 0.6520 - val_acc: 0.8953
 - f1: 0.93

Epoch 00009: f1 did not improve
Epoch 10/100
 - 3s - loss: 0.8241 - acc: 0.8841 - val_loss: 0.6383 - val_acc: 0.8983
 - f1: 0.93

Epoch 00010: f1 did not improve
Epoch 11/100
 - 3s - loss: 0.7665 - acc: 0.8848 - val_loss: 0.6216 - val_acc: 0.8983
 - f1: 0.93

Epoch 00011: f1 did not improve
testing fold 2
f1_score: 0.94
training fold 3
Train on 1373 samples, validate on 343 samples
Epoch 1/100
 - 4s - loss: 2.8993 - acc: 0.6256 - val_loss: 1.1894 - val_acc: 0.8455
 - f1: 0.90

Epoch 00001: f1 improved from -inf to 0.90296, saving model to log/1524912024/1524912273/weights_3.best.h5
Epoch 2/100
 - 3s - loss: 1.6934 - acc: 0.7742 - val_loss: 1.3244 - val_acc: 0.8455
 - f1: 0.91

Epoch 00002: f1 improved from 0.90296 to 0.90905, saving model to log/1524912024/1524912273/weights_3.best.h5
Epoch 3/100
 - 3s - loss: 1.4241 - acc: 0.8157 - val_loss: 1.4228 - val_acc: 0.8426
 - f1: 0.90

Epoch 00003: f1 did not improve
Epoch 4/100
 - 3s - loss: 1.2091 - acc: 0.8325 - val_loss: 1.1839 - val_acc: 0.8571
 - f1: 0.91

Epoch 00004: f1 improved from 0.90905 to 0.91276, saving model to log/1524912024/1524912273/weights_3.best.h5
Epoch 5/100
 - 3s - loss: 1.1342 - acc: 0.8376 - val_loss: 1.9302 - val_acc: 0.8192
 - f1: 0.89

Epoch 00005: f1 did not improve
Epoch 6/100
 - 3s - loss: 1.1195 - acc: 0.8325 - val_loss: 0.9714 - val_acc: 0.8717
 - f1: 0.93

Epoch 00006: f1 improved from 0.91276 to 0.92544, saving model to log/1524912024/1524912273/weights_3.best.h5
Epoch 7/100
 - 3s - loss: 0.9038 - acc: 0.8616 - val_loss: 1.1536 - val_acc: 0.8571
 - f1: 0.92

Epoch 00007: f1 did not improve
Epoch 8/100
 - 3s - loss: 0.9231 - acc: 0.8667 - val_loss: 1.1650 - val_acc: 0.8659
 - f1: 0.92

Epoch 00008: f1 did not improve
Epoch 9/100
 - 3s - loss: 0.8474 - acc: 0.8813 - val_loss: 1.4701 - val_acc: 0.8134
 - f1: 0.86

Epoch 00009: f1 did not improve
Epoch 10/100
 - 3s - loss: 0.8205 - acc: 0.8762 - val_loss: 0.8026 - val_acc: 0.9009
 - f1: 0.94

Epoch 00010: f1 improved from 0.92544 to 0.93660, saving model to log/1524912024/1524912273/weights_3.best.h5
Epoch 11/100
 - 3s - loss: 0.7668 - acc: 0.8784 - val_loss: 0.8081 - val_acc: 0.9067
 - f1: 0.94

Epoch 00011: f1 improved from 0.93660 to 0.93789, saving model to log/1524912024/1524912273/weights_3.best.h5
Epoch 12/100
 - 3s - loss: 0.7260 - acc: 0.8776 - val_loss: 0.7966 - val_acc: 0.9096
 - f1: 0.94

Epoch 00012: f1 improved from 0.93789 to 0.94084, saving model to log/1524912024/1524912273/weights_3.best.h5
Epoch 13/100
 - 3s - loss: 0.6720 - acc: 0.8908 - val_loss: 0.8697 - val_acc: 0.8776
 - f1: 0.93

Epoch 00013: f1 did not improve
Epoch 14/100
 - 3s - loss: 0.6752 - acc: 0.8893 - val_loss: 0.7313 - val_acc: 0.9038
 - f1: 0.94

Epoch 00014: f1 did not improve
Epoch 15/100
 - 3s - loss: 0.6868 - acc: 0.8958 - val_loss: 1.2461 - val_acc: 0.8017
 - f1: 0.84

Epoch 00015: f1 did not improve
Epoch 16/100
 - 3s - loss: 0.6591 - acc: 0.8980 - val_loss: 0.6622 - val_acc: 0.9067
 - f1: 0.94

Epoch 00016: f1 improved from 0.94084 to 0.94132, saving model to log/1524912024/1524912273/weights_3.best.h5
Epoch 17/100
 - 3s - loss: 0.6265 - acc: 0.8813 - val_loss: 0.6959 - val_acc: 0.9038
 - f1: 0.94

Epoch 00017: f1 did not improve
Epoch 18/100
 - 3s - loss: 0.6170 - acc: 0.8958 - val_loss: 0.7226 - val_acc: 0.8863
 - f1: 0.93

Epoch 00018: f1 did not improve
Epoch 19/100
 - 3s - loss: 0.5891 - acc: 0.8900 - val_loss: 0.6417 - val_acc: 0.9096
 - f1: 0.94

Epoch 00019: f1 improved from 0.94132 to 0.94374, saving model to log/1524912024/1524912273/weights_3.best.h5
Epoch 20/100
 - 3s - loss: 0.5517 - acc: 0.9017 - val_loss: 0.6782 - val_acc: 0.9096
 - f1: 0.94

Epoch 00020: f1 improved from 0.94374 to 0.94487, saving model to log/1524912024/1524912273/weights_3.best.h5
Epoch 21/100
 - 3s - loss: 0.5210 - acc: 0.9126 - val_loss: 0.6577 - val_acc: 0.9067
 - f1: 0.94

Epoch 00021: f1 did not improve
Epoch 22/100
 - 3s - loss: 0.5608 - acc: 0.8966 - val_loss: 0.6240 - val_acc: 0.9096
 - f1: 0.94

Epoch 00022: f1 did not improve
Epoch 23/100
 - 3s - loss: 0.4629 - acc: 0.9184 - val_loss: 0.5936 - val_acc: 0.9125
 - f1: 0.94

Epoch 00023: f1 did not improve
Epoch 24/100
 - 3s - loss: 0.4807 - acc: 0.9119 - val_loss: 0.5697 - val_acc: 0.9155
 - f1: 0.95

Epoch 00024: f1 improved from 0.94487 to 0.94790, saving model to log/1524912024/1524912273/weights_3.best.h5
Epoch 25/100
 - 3s - loss: 0.4815 - acc: 0.9162 - val_loss: 0.5848 - val_acc: 0.9038
 - f1: 0.94

Epoch 00025: f1 did not improve
Epoch 26/100
 - 3s - loss: 0.4439 - acc: 0.9133 - val_loss: 0.6513 - val_acc: 0.9038
 - f1: 0.94

Epoch 00026: f1 did not improve
Epoch 27/100
 - 3s - loss: 0.4523 - acc: 0.9068 - val_loss: 0.5979 - val_acc: 0.9096
 - f1: 0.94

Epoch 00027: f1 did not improve
Epoch 28/100
 - 3s - loss: 0.4532 - acc: 0.9133 - val_loss: 0.5855 - val_acc: 0.8980
 - f1: 0.94

Epoch 00028: f1 did not improve
Epoch 29/100
 - 3s - loss: 0.4452 - acc: 0.9133 - val_loss: 0.5827 - val_acc: 0.9125
 - f1: 0.95

Epoch 00029: f1 did not improve
testing fold 3
f1_score: 0.95
training fold 4
Train on 1374 samples, validate on 342 samples
Epoch 1/100
 - 4s - loss: 3.1255 - acc: 0.6230 - val_loss: 0.9193 - val_acc: 0.8509
 - f1: 0.91

Epoch 00001: f1 improved from -inf to 0.90634, saving model to log/1524912024/1524912273/weights_4.best.h5
Epoch 2/100
 - 3s - loss: 1.7599 - acc: 0.7620 - val_loss: 2.4086 - val_acc: 0.7895
 - f1: 0.87

Epoch 00002: f1 did not improve
Epoch 3/100
 - 3s - loss: 1.5163 - acc: 0.8130 - val_loss: 0.7678 - val_acc: 0.8889
 - f1: 0.93

Epoch 00003: f1 improved from 0.90634 to 0.93054, saving model to log/1524912024/1524912273/weights_4.best.h5
Epoch 4/100
 - 3s - loss: 1.3179 - acc: 0.8159 - val_loss: 0.6971 - val_acc: 0.8977
 - f1: 0.93

Epoch 00004: f1 improved from 0.93054 to 0.93289, saving model to log/1524912024/1524912273/weights_4.best.h5
Epoch 5/100
 - 3s - loss: 1.1661 - acc: 0.8341 - val_loss: 0.7561 - val_acc: 0.9006
 - f1: 0.94

Epoch 00005: f1 improved from 0.93289 to 0.93517, saving model to log/1524912024/1524912273/weights_4.best.h5
Epoch 6/100
 - 3s - loss: 1.1092 - acc: 0.8319 - val_loss: 0.6480 - val_acc: 0.9094
 - f1: 0.94

Epoch 00006: f1 improved from 0.93517 to 0.94157, saving model to log/1524912024/1524912273/weights_4.best.h5
Epoch 7/100
 - 3s - loss: 1.0675 - acc: 0.8537 - val_loss: 0.6281 - val_acc: 0.9006
 - f1: 0.94

Epoch 00007: f1 did not improve
Epoch 8/100
 - 3s - loss: 0.9644 - acc: 0.8624 - val_loss: 0.6779 - val_acc: 0.8947
 - f1: 0.93

Epoch 00008: f1 did not improve
Epoch 9/100
 - 3s - loss: 0.9041 - acc: 0.8566 - val_loss: 0.6834 - val_acc: 0.8947
 - f1: 0.94

Epoch 00009: f1 did not improve
Epoch 10/100
 - 3s - loss: 0.8150 - acc: 0.8719 - val_loss: 0.7075 - val_acc: 0.8889
 - f1: 0.93

Epoch 00010: f1 did not improve
Epoch 11/100
 - 3s - loss: 0.8587 - acc: 0.8624 - val_loss: 0.5541 - val_acc: 0.8947
 - f1: 0.94

Epoch 00011: f1 did not improve
testing fold 4
f1_score: 0.94
training fold 5
Train on 1374 samples, validate on 342 samples
Epoch 1/100
 - 4s - loss: 2.9114 - acc: 0.6325 - val_loss: 1.1615 - val_acc: 0.8596
 - f1: 0.91

Epoch 00001: f1 improved from -inf to 0.91410, saving model to log/1524912024/1524912273/weights_5.best.h5
Epoch 2/100
 - 3s - loss: 1.6655 - acc: 0.7744 - val_loss: 0.7726 - val_acc: 0.9006
 - f1: 0.94

Epoch 00002: f1 improved from 0.91410 to 0.93546, saving model to log/1524912024/1524912273/weights_5.best.h5
Epoch 3/100
 - 3s - loss: 1.5030 - acc: 0.7991 - val_loss: 0.7649 - val_acc: 0.9123
 - f1: 0.94

Epoch 00003: f1 improved from 0.93546 to 0.94171, saving model to log/1524912024/1524912273/weights_5.best.h5
Epoch 4/100
 - 3s - loss: 1.3701 - acc: 0.8071 - val_loss: 1.4514 - val_acc: 0.8333
 - f1: 0.91

Epoch 00004: f1 did not improve
Epoch 5/100
 - 3s - loss: 1.1998 - acc: 0.8421 - val_loss: 0.7238 - val_acc: 0.8977
 - f1: 0.94

Epoch 00005: f1 did not improve
Epoch 6/100
 - 3s - loss: 1.0546 - acc: 0.8443 - val_loss: 0.7100 - val_acc: 0.8947
 - f1: 0.93

Epoch 00006: f1 did not improve
Epoch 7/100
 - 3s - loss: 1.0892 - acc: 0.8457 - val_loss: 1.0793 - val_acc: 0.8626
 - f1: 0.92

Epoch 00007: f1 did not improve
Epoch 8/100
 - 3s - loss: 0.9026 - acc: 0.8559 - val_loss: 1.8745 - val_acc: 0.7427
 - f1: 0.74

Epoch 00008: f1 did not improve
testing fold 5
f1_score: 0.94
model_config: {'lexical_feature': [1, 2, 3, 4]}, f1_avg = 0.94
training fold 1
Train on 1371 samples, validate on 345 samples
Epoch 1/100
 - 5s - loss: 3.4383 - acc: 0.5959 - val_loss: 0.9732 - val_acc: 0.8232
 - f1: 0.88

Epoch 00001: f1 improved from -inf to 0.87601, saving model to log/1524912024/1524912536/weights_1.best.h5
Epoch 2/100
 - 5s - loss: 2.1128 - acc: 0.7287 - val_loss: 0.9316 - val_acc: 0.8580
 - f1: 0.90

Epoch 00002: f1 improved from 0.87601 to 0.90272, saving model to log/1524912024/1524912536/weights_1.best.h5
Epoch 3/100
 - 5s - loss: 2.2816 - acc: 0.7469 - val_loss: 1.0240 - val_acc: 0.8638
 - f1: 0.90

Epoch 00003: f1 did not improve
Epoch 4/100
 - 5s - loss: 2.2937 - acc: 0.7702 - val_loss: 1.7824 - val_acc: 0.8406
 - f1: 0.89

Epoch 00004: f1 did not improve
Epoch 5/100
 - 5s - loss: 2.0321 - acc: 0.7936 - val_loss: 2.0056 - val_acc: 0.8290
 - f1: 0.89

Epoch 00005: f1 did not improve
Epoch 6/100
 - 5s - loss: 2.3205 - acc: 0.7834 - val_loss: 1.3533 - val_acc: 0.8725
 - f1: 0.91

Epoch 00006: f1 improved from 0.90272 to 0.91379, saving model to log/1524912024/1524912536/weights_1.best.h5
Epoch 7/100
 - 5s - loss: 2.3452 - acc: 0.8125 - val_loss: 3.1278 - val_acc: 0.7942
 - f1: 0.86

Epoch 00007: f1 did not improve
Epoch 8/100
 - 5s - loss: 2.5315 - acc: 0.8023 - val_loss: 1.8801 - val_acc: 0.8522
 - f1: 0.90

Epoch 00008: f1 did not improve
Epoch 9/100
 - 5s - loss: 2.1506 - acc: 0.8235 - val_loss: 1.5193 - val_acc: 0.8783
 - f1: 0.91

Epoch 00009: f1 did not improve
Epoch 10/100
 - 5s - loss: 2.4521 - acc: 0.8213 - val_loss: 1.2246 - val_acc: 0.9043
 - f1: 0.93

Epoch 00010: f1 improved from 0.91379 to 0.93438, saving model to log/1524912024/1524912536/weights_1.best.h5
Epoch 11/100
 - 5s - loss: 2.1864 - acc: 0.8330 - val_loss: 1.4503 - val_acc: 0.8957
 - f1: 0.92

Epoch 00011: f1 did not improve
Epoch 12/100
 - 5s - loss: 2.1552 - acc: 0.8381 - val_loss: 1.4205 - val_acc: 0.9014
 - f1: 0.93

Epoch 00012: f1 did not improve
Epoch 13/100
 - 5s - loss: 2.2382 - acc: 0.8403 - val_loss: 1.4238 - val_acc: 0.9014
 - f1: 0.93

Epoch 00013: f1 did not improve
Epoch 14/100
 - 5s - loss: 2.3283 - acc: 0.8330 - val_loss: 1.4537 - val_acc: 0.8899
 - f1: 0.92

Epoch 00014: f1 did not improve
Epoch 15/100
 - 5s - loss: 2.3797 - acc: 0.8286 - val_loss: 1.7146 - val_acc: 0.8899
 - f1: 0.92

Epoch 00015: f1 did not improve
testing fold 1
f1_score: 0.93
training fold 2
Train on 1372 samples, validate on 344 samples
Epoch 1/100
 - 5s - loss: 3.2635 - acc: 0.5838 - val_loss: 1.6875 - val_acc: 0.7703
 - f1: 0.84

Epoch 00001: f1 improved from -inf to 0.83936, saving model to log/1524912024/1524912536/weights_2.best.h5
Epoch 2/100
 - 5s - loss: 2.4578 - acc: 0.7150 - val_loss: 2.8889 - val_acc: 0.6570
 - f1: 0.71

Epoch 00002: f1 did not improve
Epoch 3/100
 - 5s - loss: 2.4704 - acc: 0.7427 - val_loss: 3.0885 - val_acc: 0.6686
 - f1: 0.73

Epoch 00003: f1 did not improve
Epoch 4/100
 - 5s - loss: 2.2683 - acc: 0.7741 - val_loss: 1.3862 - val_acc: 0.8198
 - f1: 0.89

Epoch 00004: f1 improved from 0.83936 to 0.88834, saving model to log/1524912024/1524912536/weights_2.best.h5
Epoch 5/100
 - 5s - loss: 2.3990 - acc: 0.7704 - val_loss: 2.1324 - val_acc: 0.8227
 - f1: 0.88

Epoch 00005: f1 did not improve
Epoch 6/100
 - 5s - loss: 2.2722 - acc: 0.7974 - val_loss: 1.4396 - val_acc: 0.8459
 - f1: 0.90

Epoch 00006: f1 improved from 0.88834 to 0.89786, saving model to log/1524912024/1524912536/weights_2.best.h5
Epoch 7/100
 - 5s - loss: 2.3210 - acc: 0.7959 - val_loss: 1.6007 - val_acc: 0.8430
 - f1: 0.89

Epoch 00007: f1 did not improve
Epoch 8/100
 - 5s - loss: 2.4732 - acc: 0.8083 - val_loss: 1.4698 - val_acc: 0.8634
 - f1: 0.91

Epoch 00008: f1 improved from 0.89786 to 0.90951, saving model to log/1524912024/1524912536/weights_2.best.h5
Epoch 9/100
 - 5s - loss: 2.1939 - acc: 0.8265 - val_loss: 1.7280 - val_acc: 0.8576
 - f1: 0.90

Epoch 00009: f1 did not improve
Epoch 10/100
 - 5s - loss: 2.2642 - acc: 0.8214 - val_loss: 2.7540 - val_acc: 0.8140
 - f1: 0.88

Epoch 00010: f1 did not improve
Epoch 11/100
 - 5s - loss: 2.3302 - acc: 0.8273 - val_loss: 1.9020 - val_acc: 0.8372
 - f1: 0.89

Epoch 00011: f1 did not improve
Epoch 12/100
 - 5s - loss: 2.3445 - acc: 0.8309 - val_loss: 4.1149 - val_acc: 0.7471
 - f1: 0.83

Epoch 00012: f1 did not improve
Epoch 13/100
 - 5s - loss: 2.7577 - acc: 0.8207 - val_loss: 1.8135 - val_acc: 0.8547
 - f1: 0.90

Epoch 00013: f1 did not improve
testing fold 2
f1_score: 0.91
training fold 3
Train on 1373 samples, validate on 343 samples
Epoch 1/100
 - 5s - loss: 3.1862 - acc: 0.6038 - val_loss: 1.3816 - val_acc: 0.8105
 - f1: 0.87

Epoch 00001: f1 improved from -inf to 0.87207, saving model to log/1524912024/1524912536/weights_3.best.h5
Epoch 2/100
 - 5s - loss: 2.6488 - acc: 0.7058 - val_loss: 1.6507 - val_acc: 0.8251
 - f1: 0.86

Epoch 00002: f1 did not improve
Epoch 3/100
 - 5s - loss: 2.6214 - acc: 0.7334 - val_loss: 1.9905 - val_acc: 0.7638
 - f1: 0.81

Epoch 00003: f1 did not improve
Epoch 4/100
 - 5s - loss: 2.3885 - acc: 0.7677 - val_loss: 1.1267 - val_acc: 0.8659
 - f1: 0.91

Epoch 00004: f1 improved from 0.87207 to 0.91009, saving model to log/1524912024/1524912536/weights_3.best.h5
Epoch 5/100
 - 5s - loss: 2.3287 - acc: 0.8041 - val_loss: 1.4508 - val_acc: 0.8426
 - f1: 0.91

Epoch 00005: f1 did not improve
Epoch 6/100
 - 5s - loss: 2.2966 - acc: 0.7990 - val_loss: 1.5105 - val_acc: 0.8630
 - f1: 0.91

Epoch 00006: f1 did not improve
Epoch 7/100
 - 5s - loss: 2.2007 - acc: 0.8034 - val_loss: 1.3235 - val_acc: 0.8805
 - f1: 0.92

Epoch 00007: f1 improved from 0.91009 to 0.92211, saving model to log/1524912024/1524912536/weights_3.best.h5
Epoch 8/100
 - 5s - loss: 2.1122 - acc: 0.8296 - val_loss: 1.5995 - val_acc: 0.8892
 - f1: 0.92

Epoch 00008: f1 improved from 0.92211 to 0.92461, saving model to log/1524912024/1524912536/weights_3.best.h5
Epoch 9/100
 - 5s - loss: 2.1555 - acc: 0.8318 - val_loss: 1.4356 - val_acc: 0.8834
 - f1: 0.91

Epoch 00009: f1 did not improve
Epoch 10/100
 - 5s - loss: 2.2718 - acc: 0.8216 - val_loss: 1.3934 - val_acc: 0.9009
 - f1: 0.94

Epoch 00010: f1 improved from 0.92461 to 0.93834, saving model to log/1524912024/1524912536/weights_3.best.h5
Epoch 11/100
 - 5s - loss: 2.2133 - acc: 0.8296 - val_loss: 1.4307 - val_acc: 0.8980
 - f1: 0.94

Epoch 00011: f1 improved from 0.93834 to 0.93868, saving model to log/1524912024/1524912536/weights_3.best.h5
Epoch 12/100
 - 5s - loss: 2.2376 - acc: 0.8369 - val_loss: 1.3935 - val_acc: 0.8921
 - f1: 0.93

Epoch 00012: f1 did not improve
Epoch 13/100
 - 5s - loss: 2.0613 - acc: 0.8492 - val_loss: 1.6111 - val_acc: 0.8950
 - f1: 0.94

Epoch 00013: f1 improved from 0.93868 to 0.93871, saving model to log/1524912024/1524912536/weights_3.best.h5
Epoch 14/100
 - 5s - loss: 1.9715 - acc: 0.8551 - val_loss: 1.6459 - val_acc: 0.8921
 - f1: 0.93

Epoch 00014: f1 did not improve
Epoch 15/100
 - 5s - loss: 2.0581 - acc: 0.8492 - val_loss: 1.6012 - val_acc: 0.8834
 - f1: 0.93

Epoch 00015: f1 did not improve
Epoch 16/100
 - 5s - loss: 2.0971 - acc: 0.8529 - val_loss: 1.3729 - val_acc: 0.8950
 - f1: 0.93

Epoch 00016: f1 did not improve
Epoch 17/100
 - 5s - loss: 2.2111 - acc: 0.8434 - val_loss: 1.8894 - val_acc: 0.8746
 - f1: 0.92

Epoch 00017: f1 did not improve
Epoch 18/100
 - 5s - loss: 2.1898 - acc: 0.8551 - val_loss: 1.6676 - val_acc: 0.9009
 - f1: 0.94

Epoch 00018: f1 improved from 0.93871 to 0.94019, saving model to log/1524912024/1524912536/weights_3.best.h5
Epoch 19/100
 - 5s - loss: 2.1711 - acc: 0.8543 - val_loss: 1.6854 - val_acc: 0.9038
 - f1: 0.94

Epoch 00019: f1 improved from 0.94019 to 0.94122, saving model to log/1524912024/1524912536/weights_3.best.h5
Epoch 20/100
 - 5s - loss: 1.9816 - acc: 0.8667 - val_loss: 1.8062 - val_acc: 0.8892
 - f1: 0.93

Epoch 00020: f1 did not improve
Epoch 21/100
 - 5s - loss: 2.0310 - acc: 0.8645 - val_loss: 1.4757 - val_acc: 0.9125
 - f1: 0.94

Epoch 00021: f1 improved from 0.94122 to 0.94491, saving model to log/1524912024/1524912536/weights_3.best.h5
Epoch 22/100
 - 5s - loss: 2.0910 - acc: 0.8660 - val_loss: 1.7268 - val_acc: 0.9067
 - f1: 0.94

Epoch 00022: f1 did not improve
Epoch 23/100
 - 5s - loss: 2.2674 - acc: 0.8587 - val_loss: 1.7062 - val_acc: 0.8863
 - f1: 0.93

Epoch 00023: f1 did not improve
Epoch 24/100
 - 5s - loss: 2.0804 - acc: 0.8689 - val_loss: 1.6807 - val_acc: 0.8892
 - f1: 0.93

Epoch 00024: f1 did not improve
Epoch 25/100
 - 5s - loss: 2.1382 - acc: 0.8631 - val_loss: 1.7347 - val_acc: 0.8980
 - f1: 0.94

Epoch 00025: f1 did not improve
Epoch 26/100
 - 5s - loss: 2.0739 - acc: 0.8711 - val_loss: 1.9024 - val_acc: 0.8950
 - f1: 0.93

Epoch 00026: f1 did not improve
testing fold 3
f1_score: 0.94
training fold 4
Train on 1374 samples, validate on 342 samples
Epoch 1/100
 - 5s - loss: 3.4017 - acc: 0.6033 - val_loss: 1.6909 - val_acc: 0.7982
 - f1: 0.86

Epoch 00001: f1 improved from -inf to 0.86237, saving model to log/1524912024/1524912536/weights_4.best.h5
Epoch 2/100
 - 5s - loss: 2.6116 - acc: 0.7016 - val_loss: 2.6915 - val_acc: 0.7895
 - f1: 0.86

Epoch 00002: f1 did not improve
Epoch 3/100
 - 5s - loss: 2.3871 - acc: 0.7475 - val_loss: 1.4292 - val_acc: 0.8509
 - f1: 0.87

Epoch 00003: f1 improved from 0.86237 to 0.87434, saving model to log/1524912024/1524912536/weights_4.best.h5
Epoch 4/100
 - 5s - loss: 2.3867 - acc: 0.7606 - val_loss: 1.2107 - val_acc: 0.8684
 - f1: 0.91

Epoch 00004: f1 improved from 0.87434 to 0.90652, saving model to log/1524912024/1524912536/weights_4.best.h5
Epoch 5/100
 - 5s - loss: 2.3643 - acc: 0.7795 - val_loss: 1.2740 - val_acc: 0.8626
 - f1: 0.90

Epoch 00005: f1 did not improve
Epoch 6/100
 - 5s - loss: 2.1786 - acc: 0.8064 - val_loss: 1.2005 - val_acc: 0.8889
 - f1: 0.91

Epoch 00006: f1 improved from 0.90652 to 0.91061, saving model to log/1524912024/1524912536/weights_4.best.h5
Epoch 7/100
 - 5s - loss: 2.2065 - acc: 0.8144 - val_loss: 2.4077 - val_acc: 0.8275
 - f1: 0.89

Epoch 00007: f1 did not improve
Epoch 8/100
 - 5s - loss: 2.1851 - acc: 0.8210 - val_loss: 1.1810 - val_acc: 0.9035
 - f1: 0.93

Epoch 00008: f1 improved from 0.91061 to 0.92612, saving model to log/1524912024/1524912536/weights_4.best.h5
Epoch 9/100
 - 5s - loss: 2.2541 - acc: 0.8333 - val_loss: 1.5630 - val_acc: 0.8596
 - f1: 0.90

Epoch 00009: f1 did not improve
Epoch 10/100
 - 5s - loss: 2.3654 - acc: 0.8210 - val_loss: 1.4627 - val_acc: 0.8860
 - f1: 0.91

Epoch 00010: f1 did not improve
Epoch 11/100
 - 5s - loss: 2.6200 - acc: 0.8137 - val_loss: 1.4220 - val_acc: 0.8860
 - f1: 0.91

Epoch 00011: f1 did not improve
Epoch 12/100
 - 5s - loss: 2.3547 - acc: 0.8319 - val_loss: 1.6345 - val_acc: 0.8743
 - f1: 0.91

Epoch 00012: f1 did not improve
Epoch 13/100
 - 5s - loss: 2.2844 - acc: 0.8326 - val_loss: 2.0873 - val_acc: 0.8538
 - f1: 0.90

Epoch 00013: f1 did not improve
testing fold 4
f1_score: 0.93
training fold 5
Train on 1374 samples, validate on 342 samples
Epoch 1/100
 - 5s - loss: 3.7116 - acc: 0.5706 - val_loss: 1.8485 - val_acc: 0.7895
 - f1: 0.87

Epoch 00001: f1 improved from -inf to 0.87072, saving model to log/1524912024/1524912536/weights_5.best.h5
Epoch 2/100
 - 5s - loss: 2.4070 - acc: 0.7103 - val_loss: 1.4550 - val_acc: 0.8333
 - f1: 0.89

Epoch 00002: f1 improved from 0.87072 to 0.88713, saving model to log/1524912024/1524912536/weights_5.best.h5
Epoch 3/100
 - 5s - loss: 2.2055 - acc: 0.7722 - val_loss: 2.0857 - val_acc: 0.8187
 - f1: 0.88

Epoch 00003: f1 did not improve
Epoch 4/100
 - 5s - loss: 2.2597 - acc: 0.7693 - val_loss: 1.1793 - val_acc: 0.8567
 - f1: 0.91

Epoch 00004: f1 improved from 0.88713 to 0.90584, saving model to log/1524912024/1524912536/weights_5.best.h5
Epoch 5/100
 - 5s - loss: 2.4486 - acc: 0.7809 - val_loss: 2.0053 - val_acc: 0.8333
 - f1: 0.90

Epoch 00005: f1 did not improve
Epoch 6/100
 - 5s - loss: 2.3115 - acc: 0.8028 - val_loss: 1.4379 - val_acc: 0.8772
 - f1: 0.92

Epoch 00006: f1 improved from 0.90584 to 0.91766, saving model to log/1524912024/1524912536/weights_5.best.h5
Epoch 7/100
 - 5s - loss: 2.2603 - acc: 0.8130 - val_loss: 2.2459 - val_acc: 0.8509
 - f1: 0.91

Epoch 00007: f1 did not improve
Epoch 8/100
 - 5s - loss: 2.3878 - acc: 0.8173 - val_loss: 2.1175 - val_acc: 0.8538
 - f1: 0.91

Epoch 00008: f1 did not improve
Epoch 9/100
 - 5s - loss: 2.5097 - acc: 0.8086 - val_loss: 2.6923 - val_acc: 0.8216
 - f1: 0.90

Epoch 00009: f1 did not improve
Epoch 10/100
 - 5s - loss: 2.4422 - acc: 0.8246 - val_loss: 2.0213 - val_acc: 0.8626
 - f1: 0.91

Epoch 00010: f1 did not improve
Epoch 11/100
 - 5s - loss: 2.2191 - acc: 0.8341 - val_loss: 2.2099 - val_acc: 0.8480
 - f1: 0.91

Epoch 00011: f1 did not improve
testing fold 5
f1_score: 0.92
model_config: {'piecewise_max_pool': True}, f1_avg = 0.93
training fold 1
Train on 1371 samples, validate on 345 samples
Epoch 1/100
 - 6s - loss: 3.9829 - acc: 0.4668 - val_loss: 0.6572 - val_acc: 0.7913
 - f1: 0.85

Epoch 00001: f1 improved from -inf to 0.85262, saving model to log/1524912024/1524912939/weights_1.best.h5
Epoch 2/100
 - 6s - loss: 2.6385 - acc: 0.6287 - val_loss: 1.1857 - val_acc: 0.7623
 - f1: 0.84

Epoch 00002: f1 did not improve
Epoch 3/100
 - 6s - loss: 2.2291 - acc: 0.6929 - val_loss: 3.9442 - val_acc: 0.7130
 - f1: 0.80

Epoch 00003: f1 did not improve
Epoch 4/100
 - 6s - loss: 3.4654 - acc: 0.7119 - val_loss: 1.1247 - val_acc: 0.7797
 - f1: 0.86

Epoch 00004: f1 improved from 0.85262 to 0.85548, saving model to log/1524912024/1524912939/weights_1.best.h5
Epoch 5/100
 - 6s - loss: 2.5102 - acc: 0.7024 - val_loss: 1.3918 - val_acc: 0.8116
 - f1: 0.89

Epoch 00005: f1 improved from 0.85548 to 0.88523, saving model to log/1524912024/1524912939/weights_1.best.h5
Epoch 6/100
 - 6s - loss: 1.9672 - acc: 0.7469 - val_loss: 0.9023 - val_acc: 0.8116
 - f1: 0.86

Epoch 00006: f1 did not improve
Epoch 7/100
 - 6s - loss: 2.1138 - acc: 0.7564 - val_loss: 0.8057 - val_acc: 0.8522
 - f1: 0.89

Epoch 00007: f1 improved from 0.88523 to 0.89378, saving model to log/1524912024/1524912939/weights_1.best.h5
Epoch 8/100
 - 6s - loss: 1.8732 - acc: 0.7783 - val_loss: 1.0996 - val_acc: 0.8464
 - f1: 0.87

Epoch 00008: f1 did not improve
Epoch 9/100
 - 6s - loss: 1.9135 - acc: 0.7790 - val_loss: 2.0729 - val_acc: 0.8203
 - f1: 0.88

Epoch 00009: f1 did not improve
Epoch 10/100
 - 6s - loss: 2.0601 - acc: 0.7702 - val_loss: 2.7587 - val_acc: 0.6638
 - f1: 0.72

Epoch 00010: f1 did not improve
Epoch 11/100
 - 6s - loss: 2.2240 - acc: 0.7702 - val_loss: 5.0799 - val_acc: 0.6464
 - f1: 0.59

Epoch 00011: f1 did not improve
Epoch 12/100
 - 6s - loss: 2.6732 - acc: 0.7673 - val_loss: 1.2878 - val_acc: 0.8667
 - f1: 0.91

Epoch 00012: f1 improved from 0.89378 to 0.90880, saving model to log/1524912024/1524912939/weights_1.best.h5
Epoch 13/100
 - 6s - loss: 1.9749 - acc: 0.8082 - val_loss: 3.5656 - val_acc: 0.7507
 - f1: 0.84

Epoch 00013: f1 did not improve
Epoch 14/100
 - 6s - loss: 2.3231 - acc: 0.8016 - val_loss: 1.1119 - val_acc: 0.8696
 - f1: 0.91

Epoch 00014: f1 improved from 0.90880 to 0.90894, saving model to log/1524912024/1524912939/weights_1.best.h5
Epoch 15/100
 - 6s - loss: 1.9450 - acc: 0.8111 - val_loss: 5.4336 - val_acc: 0.5797
 - f1: 0.53

Epoch 00015: f1 did not improve
Epoch 16/100
 - 6s - loss: 2.4079 - acc: 0.7863 - val_loss: 1.1751 - val_acc: 0.8638
 - f1: 0.90

Epoch 00016: f1 did not improve
Epoch 17/100
 - 6s - loss: 2.0145 - acc: 0.8038 - val_loss: 0.9805 - val_acc: 0.8870
 - f1: 0.92

Epoch 00017: f1 improved from 0.90894 to 0.91898, saving model to log/1524912024/1524912939/weights_1.best.h5
Epoch 18/100
 - 6s - loss: 2.0586 - acc: 0.8067 - val_loss: 1.0045 - val_acc: 0.8986
 - f1: 0.93

Epoch 00018: f1 improved from 0.91898 to 0.92595, saving model to log/1524912024/1524912939/weights_1.best.h5
Epoch 19/100
 - 6s - loss: 1.9873 - acc: 0.8228 - val_loss: 1.5411 - val_acc: 0.8725
 - f1: 0.91

Epoch 00019: f1 did not improve
Epoch 20/100
 - 6s - loss: 1.8929 - acc: 0.8279 - val_loss: 1.8073 - val_acc: 0.8551
 - f1: 0.90

Epoch 00020: f1 did not improve
Epoch 21/100
 - 6s - loss: 1.9982 - acc: 0.8228 - val_loss: 1.0314 - val_acc: 0.8725
 - f1: 0.91

Epoch 00021: f1 did not improve
Epoch 22/100
 - 6s - loss: 1.9206 - acc: 0.8301 - val_loss: 1.0625 - val_acc: 0.8841
 - f1: 0.92

Epoch 00022: f1 did not improve
Epoch 23/100
 - 6s - loss: 1.9471 - acc: 0.8249 - val_loss: 1.1168 - val_acc: 0.8696
 - f1: 0.90

Epoch 00023: f1 did not improve
testing fold 1
f1_score: 0.93
training fold 2
Train on 1372 samples, validate on 344 samples
Epoch 1/100
 - 6s - loss: 4.1160 - acc: 0.4512 - val_loss: 4.7785 - val_acc: 0.4244
 - f1: 0.48

Epoch 00001: f1 improved from -inf to 0.47565, saving model to log/1524912024/1524912939/weights_2.best.h5
Epoch 2/100
 - 6s - loss: 2.7294 - acc: 0.6378 - val_loss: 2.0743 - val_acc: 0.6134
 - f1: 0.53

Epoch 00002: f1 improved from 0.47565 to 0.53057, saving model to log/1524912024/1524912939/weights_2.best.h5
Epoch 3/100
 - 6s - loss: 2.3201 - acc: 0.6880 - val_loss: 0.8633 - val_acc: 0.7994
 - f1: 0.86

Epoch 00003: f1 improved from 0.53057 to 0.85744, saving model to log/1524912024/1524912939/weights_2.best.h5
Epoch 4/100
 - 6s - loss: 1.9796 - acc: 0.7303 - val_loss: 1.4337 - val_acc: 0.7907
 - f1: 0.87

Epoch 00004: f1 improved from 0.85744 to 0.87029, saving model to log/1524912024/1524912939/weights_2.best.h5
Epoch 5/100
 - 6s - loss: 2.0187 - acc: 0.7303 - val_loss: 2.3007 - val_acc: 0.7907
 - f1: 0.87

Epoch 00005: f1 did not improve
Epoch 6/100
 - 6s - loss: 2.1063 - acc: 0.7318 - val_loss: 2.8156 - val_acc: 0.7791
 - f1: 0.85

Epoch 00006: f1 did not improve
Epoch 7/100
 - 6s - loss: 2.0735 - acc: 0.7456 - val_loss: 1.2527 - val_acc: 0.8227
 - f1: 0.88

Epoch 00007: f1 improved from 0.87029 to 0.87574, saving model to log/1524912024/1524912939/weights_2.best.h5
Epoch 8/100
 - 6s - loss: 1.7508 - acc: 0.7777 - val_loss: 3.4828 - val_acc: 0.7645
 - f1: 0.84

Epoch 00008: f1 did not improve
Epoch 9/100
 - 6s - loss: 2.2564 - acc: 0.7573 - val_loss: 1.1389 - val_acc: 0.8343
 - f1: 0.88

Epoch 00009: f1 improved from 0.87574 to 0.88446, saving model to log/1524912024/1524912939/weights_2.best.h5
Epoch 10/100
 - 6s - loss: 2.1358 - acc: 0.7551 - val_loss: 1.1499 - val_acc: 0.8488
 - f1: 0.89

Epoch 00010: f1 improved from 0.88446 to 0.89112, saving model to log/1524912024/1524912939/weights_2.best.h5
Epoch 11/100
 - 6s - loss: 2.0330 - acc: 0.7813 - val_loss: 1.4345 - val_acc: 0.8343
 - f1: 0.87

Epoch 00011: f1 did not improve
Epoch 12/100
 - 6s - loss: 1.9557 - acc: 0.7952 - val_loss: 1.1511 - val_acc: 0.8459
 - f1: 0.89

Epoch 00012: f1 improved from 0.89112 to 0.89355, saving model to log/1524912024/1524912939/weights_2.best.h5
Epoch 13/100
 - 6s - loss: 1.7824 - acc: 0.8127 - val_loss: 1.5153 - val_acc: 0.8401
 - f1: 0.89

Epoch 00013: f1 did not improve
Epoch 14/100
 - 6s - loss: 1.8031 - acc: 0.8054 - val_loss: 3.2674 - val_acc: 0.7674
 - f1: 0.85

Epoch 00014: f1 did not improve
Epoch 15/100
 - 6s - loss: 1.9278 - acc: 0.7988 - val_loss: 2.7511 - val_acc: 0.8110
 - f1: 0.88

Epoch 00015: f1 did not improve
Epoch 16/100
 - 6s - loss: 1.9827 - acc: 0.8083 - val_loss: 1.4354 - val_acc: 0.8605
 - f1: 0.90

Epoch 00016: f1 improved from 0.89355 to 0.90354, saving model to log/1524912024/1524912939/weights_2.best.h5
Epoch 17/100
 - 6s - loss: 1.8898 - acc: 0.8076 - val_loss: 1.5558 - val_acc: 0.8576
 - f1: 0.90

Epoch 00017: f1 did not improve
Epoch 18/100
 - 6s - loss: 1.7400 - acc: 0.8214 - val_loss: 1.0876 - val_acc: 0.8430
 - f1: 0.89

Epoch 00018: f1 did not improve
Epoch 19/100
 - 6s - loss: 1.6489 - acc: 0.8338 - val_loss: 1.1611 - val_acc: 0.8517
 - f1: 0.89

Epoch 00019: f1 did not improve
Epoch 20/100
 - 6s - loss: 1.7663 - acc: 0.8280 - val_loss: 1.7569 - val_acc: 0.8547
 - f1: 0.90

Epoch 00020: f1 did not improve
Epoch 21/100
 - 6s - loss: 1.8373 - acc: 0.8207 - val_loss: 1.3006 - val_acc: 0.8488
 - f1: 0.89

Epoch 00021: f1 did not improve
testing fold 2
f1_score: 0.90
training fold 3
Train on 1373 samples, validate on 343 samples
Epoch 1/100
 - 6s - loss: 3.6729 - acc: 0.4727 - val_loss: 1.3835 - val_acc: 0.7755
 - f1: 0.85

Epoch 00001: f1 improved from -inf to 0.84822, saving model to log/1524912024/1524912939/weights_3.best.h5
Epoch 2/100
 - 6s - loss: 2.2822 - acc: 0.6533 - val_loss: 0.6695 - val_acc: 0.8280
 - f1: 0.89

Epoch 00002: f1 improved from 0.84822 to 0.88528, saving model to log/1524912024/1524912939/weights_3.best.h5
Epoch 3/100
 - 6s - loss: 2.3578 - acc: 0.6723 - val_loss: 0.7291 - val_acc: 0.8309
 - f1: 0.88

Epoch 00003: f1 did not improve
Epoch 4/100
 - 6s - loss: 2.2957 - acc: 0.6985 - val_loss: 2.5207 - val_acc: 0.7901
 - f1: 0.86

Epoch 00004: f1 did not improve
Epoch 5/100
 - 6s - loss: 2.0355 - acc: 0.7436 - val_loss: 0.7356 - val_acc: 0.8309
 - f1: 0.89

Epoch 00005: f1 improved from 0.88528 to 0.89068, saving model to log/1524912024/1524912939/weights_3.best.h5
Epoch 6/100
 - 6s - loss: 2.0575 - acc: 0.7451 - val_loss: 2.0357 - val_acc: 0.7755
 - f1: 0.86

Epoch 00006: f1 did not improve
Epoch 7/100
 - 6s - loss: 2.0884 - acc: 0.7495 - val_loss: 0.8402 - val_acc: 0.8455
 - f1: 0.89

Epoch 00007: f1 did not improve
Epoch 8/100
 - 6s - loss: 2.0388 - acc: 0.7655 - val_loss: 1.0745 - val_acc: 0.8426
 - f1: 0.89

Epoch 00008: f1 improved from 0.89068 to 0.89337, saving model to log/1524912024/1524912939/weights_3.best.h5
Epoch 9/100
 - 6s - loss: 1.7743 - acc: 0.7932 - val_loss: 1.2808 - val_acc: 0.8367
 - f1: 0.89

Epoch 00009: f1 did not improve
Epoch 10/100
 - 6s - loss: 2.2048 - acc: 0.7706 - val_loss: 1.1134 - val_acc: 0.8601
 - f1: 0.91

Epoch 00010: f1 improved from 0.89337 to 0.90824, saving model to log/1524912024/1524912939/weights_3.best.h5
Epoch 11/100
 - 6s - loss: 1.9630 - acc: 0.7844 - val_loss: 1.5432 - val_acc: 0.8338
 - f1: 0.90

Epoch 00011: f1 did not improve
Epoch 12/100
 - 6s - loss: 2.2044 - acc: 0.7786 - val_loss: 1.2201 - val_acc: 0.8659
 - f1: 0.91

Epoch 00012: f1 improved from 0.90824 to 0.91043, saving model to log/1524912024/1524912939/weights_3.best.h5
Epoch 13/100
 - 6s - loss: 1.9227 - acc: 0.7917 - val_loss: 1.0577 - val_acc: 0.8717
 - f1: 0.91

Epoch 00013: f1 improved from 0.91043 to 0.91340, saving model to log/1524912024/1524912939/weights_3.best.h5
Epoch 14/100
 - 6s - loss: 1.7340 - acc: 0.8216 - val_loss: 2.1408 - val_acc: 0.7988
 - f1: 0.83

Epoch 00014: f1 did not improve
Epoch 15/100
 - 6s - loss: 1.9415 - acc: 0.8186 - val_loss: 1.0515 - val_acc: 0.8805
 - f1: 0.92

Epoch 00015: f1 improved from 0.91340 to 0.92147, saving model to log/1524912024/1524912939/weights_3.best.h5
Epoch 16/100
 - 6s - loss: 1.9586 - acc: 0.8208 - val_loss: 1.4195 - val_acc: 0.8805
 - f1: 0.93

Epoch 00016: f1 improved from 0.92147 to 0.92781, saving model to log/1524912024/1524912939/weights_3.best.h5
Epoch 17/100
 - 6s - loss: 1.7953 - acc: 0.8259 - val_loss: 1.7656 - val_acc: 0.8542
 - f1: 0.91

Epoch 00017: f1 did not improve
Epoch 18/100
 - 6s - loss: 2.0321 - acc: 0.8237 - val_loss: 1.9180 - val_acc: 0.8513
 - f1: 0.91

Epoch 00018: f1 did not improve
Epoch 19/100
 - 6s - loss: 2.2102 - acc: 0.8106 - val_loss: 1.6973 - val_acc: 0.8513
 - f1: 0.91

Epoch 00019: f1 did not improve
Epoch 20/100
 - 6s - loss: 2.0451 - acc: 0.8186 - val_loss: 1.5164 - val_acc: 0.8717
 - f1: 0.92

Epoch 00020: f1 did not improve
Epoch 21/100
 - 5s - loss: 2.0317 - acc: 0.8288 - val_loss: 1.2754 - val_acc: 0.8805
 - f1: 0.92

Epoch 00021: f1 did not improve
testing fold 3
f1_score: 0.93
training fold 4
Train on 1374 samples, validate on 342 samples
Epoch 1/100
 - 6s - loss: 4.2962 - acc: 0.4410 - val_loss: 1.6993 - val_acc: 0.7602
 - f1: 0.84

Epoch 00001: f1 improved from -inf to 0.83820, saving model to log/1524912024/1524912939/weights_4.best.h5
Epoch 2/100
 - 6s - loss: 2.6920 - acc: 0.6325 - val_loss: 1.8242 - val_acc: 0.6871
 - f1: 0.65

Epoch 00002: f1 did not improve
Epoch 3/100
 - 6s - loss: 2.4429 - acc: 0.6812 - val_loss: 1.2478 - val_acc: 0.7807
 - f1: 0.84

Epoch 00003: f1 improved from 0.83820 to 0.84302, saving model to log/1524912024/1524912939/weights_4.best.h5
Epoch 4/100
 - 6s - loss: 2.1290 - acc: 0.7220 - val_loss: 0.8143 - val_acc: 0.8626
 - f1: 0.90

Epoch 00004: f1 improved from 0.84302 to 0.90208, saving model to log/1524912024/1524912939/weights_4.best.h5
Epoch 5/100
 - 6s - loss: 2.1206 - acc: 0.7242 - val_loss: 1.0122 - val_acc: 0.8129
 - f1: 0.86

Epoch 00005: f1 did not improve
Epoch 6/100
 - 6s - loss: 2.0308 - acc: 0.7409 - val_loss: 0.7490 - val_acc: 0.8655
 - f1: 0.89

Epoch 00006: f1 did not improve
Epoch 7/100
 - 6s - loss: 2.1582 - acc: 0.7431 - val_loss: 2.6521 - val_acc: 0.7895
 - f1: 0.86

Epoch 00007: f1 did not improve
Epoch 8/100
 - 6s - loss: 2.1352 - acc: 0.7620 - val_loss: 1.0975 - val_acc: 0.8450
 - f1: 0.89

Epoch 00008: f1 did not improve
Epoch 9/100
 - 6s - loss: 2.0048 - acc: 0.7868 - val_loss: 1.0701 - val_acc: 0.8392
 - f1: 0.88

Epoch 00009: f1 did not improve
testing fold 4
f1_score: 0.90
training fold 5
Train on 1374 samples, validate on 342 samples
Epoch 1/100
 - 6s - loss: 3.9729 - acc: 0.4796 - val_loss: 1.1120 - val_acc: 0.7865
 - f1: 0.87

Epoch 00001: f1 improved from -inf to 0.86657, saving model to log/1524912024/1524912939/weights_5.best.h5
Epoch 2/100
 - 5s - loss: 2.5116 - acc: 0.6223 - val_loss: 1.5267 - val_acc: 0.7778
 - f1: 0.84

Epoch 00002: f1 did not improve
Epoch 3/100
 - 6s - loss: 2.3724 - acc: 0.6885 - val_loss: 1.0176 - val_acc: 0.8099
 - f1: 0.88

Epoch 00003: f1 improved from 0.86657 to 0.88356, saving model to log/1524912024/1524912939/weights_5.best.h5
Epoch 4/100
 - 6s - loss: 2.2346 - acc: 0.7125 - val_loss: 1.9567 - val_acc: 0.7865
 - f1: 0.87

Epoch 00004: f1 did not improve
Epoch 5/100
 - 6s - loss: 1.9964 - acc: 0.7293 - val_loss: 0.7302 - val_acc: 0.8304
 - f1: 0.88

Epoch 00005: f1 did not improve
Epoch 6/100
 - 6s - loss: 2.0238 - acc: 0.7271 - val_loss: 0.9862 - val_acc: 0.8538
 - f1: 0.90

Epoch 00006: f1 improved from 0.88356 to 0.90090, saving model to log/1524912024/1524912939/weights_5.best.h5
Epoch 7/100
 - 6s - loss: 1.9899 - acc: 0.7496 - val_loss: 2.7228 - val_acc: 0.7807
 - f1: 0.86

Epoch 00007: f1 did not improve
Epoch 8/100
 - 6s - loss: 2.1474 - acc: 0.7344 - val_loss: 1.2793 - val_acc: 0.8158
 - f1: 0.82

Epoch 00008: f1 did not improve
Epoch 9/100
 - 6s - loss: 2.1176 - acc: 0.7482 - val_loss: 1.0496 - val_acc: 0.8333
 - f1: 0.88

Epoch 00009: f1 did not improve
Epoch 10/100
 - 6s - loss: 2.0204 - acc: 0.7671 - val_loss: 1.2985 - val_acc: 0.7982
 - f1: 0.83

Epoch 00010: f1 did not improve
Epoch 11/100
 - 6s - loss: 1.8655 - acc: 0.7838 - val_loss: 0.8035 - val_acc: 0.8801
 - f1: 0.91

Epoch 00011: f1 improved from 0.90090 to 0.90946, saving model to log/1524912024/1524912939/weights_5.best.h5
Epoch 12/100
 - 6s - loss: 1.9825 - acc: 0.7773 - val_loss: 2.4433 - val_acc: 0.7924
 - f1: 0.87

Epoch 00012: f1 did not improve
Epoch 13/100
 - 6s - loss: 1.9498 - acc: 0.7962 - val_loss: 1.7941 - val_acc: 0.8275
 - f1: 0.88

Epoch 00013: f1 did not improve
Epoch 14/100
 - 6s - loss: 1.8949 - acc: 0.7926 - val_loss: 1.5253 - val_acc: 0.8538
 - f1: 0.90

Epoch 00014: f1 did not improve
Epoch 15/100
 - 6s - loss: 1.8616 - acc: 0.7969 - val_loss: 1.7680 - val_acc: 0.8450
 - f1: 0.90

Epoch 00015: f1 did not improve
Epoch 16/100
 - 6s - loss: 1.9344 - acc: 0.7911 - val_loss: 1.0155 - val_acc: 0.8450
 - f1: 0.87

Epoch 00016: f1 did not improve
testing fold 5
f1_score: 0.91
model_config: {'attention_input': 2}, f1_avg = 0.91
training fold 1
Train on 1371 samples, validate on 345 samples
Epoch 1/100
 - 7s - loss: 3.2844 - acc: 0.6572 - val_loss: 1.4944 - val_acc: 0.8348
 - f1: 0.88

Epoch 00001: f1 improved from -inf to 0.87532, saving model to log/1524912024/1524913527/weights_1.best.h5
Epoch 2/100
 - 7s - loss: 2.2905 - acc: 0.7907 - val_loss: 1.2851 - val_acc: 0.8754
 - f1: 0.91

Epoch 00002: f1 improved from 0.87532 to 0.91464, saving model to log/1524912024/1524913527/weights_1.best.h5
Epoch 3/100
 - 7s - loss: 1.9878 - acc: 0.8235 - val_loss: 1.2315 - val_acc: 0.8841
 - f1: 0.92

Epoch 00003: f1 improved from 0.91464 to 0.91960, saving model to log/1524912024/1524913527/weights_1.best.h5
Epoch 4/100
 - 7s - loss: 2.0049 - acc: 0.8198 - val_loss: 1.2170 - val_acc: 0.8899
 - f1: 0.92

Epoch 00004: f1 did not improve
Epoch 5/100
 - 7s - loss: 1.9235 - acc: 0.8293 - val_loss: 1.3762 - val_acc: 0.8638
 - f1: 0.90

Epoch 00005: f1 did not improve
Epoch 6/100
 - 7s - loss: 1.6623 - acc: 0.8541 - val_loss: 1.2717 - val_acc: 0.9130
 - f1: 0.94

Epoch 00006: f1 improved from 0.91960 to 0.94056, saving model to log/1524912024/1524913527/weights_1.best.h5
Epoch 7/100
 - 7s - loss: 1.7502 - acc: 0.8600 - val_loss: 1.2948 - val_acc: 0.9101
 - f1: 0.94

Epoch 00007: f1 did not improve
Epoch 8/100
 - 7s - loss: 1.8063 - acc: 0.8425 - val_loss: 1.2537 - val_acc: 0.9217
 - f1: 0.95

Epoch 00008: f1 improved from 0.94056 to 0.94732, saving model to log/1524912024/1524913527/weights_1.best.h5
Epoch 9/100
 - 7s - loss: 1.7160 - acc: 0.8600 - val_loss: 1.1764 - val_acc: 0.9014
 - f1: 0.93

Epoch 00009: f1 did not improve
Epoch 10/100
 - 7s - loss: 1.7357 - acc: 0.8614 - val_loss: 1.5794 - val_acc: 0.8696
 - f1: 0.92

Epoch 00010: f1 did not improve
Epoch 11/100
 - 7s - loss: 1.7138 - acc: 0.8731 - val_loss: 1.9150 - val_acc: 0.8725
 - f1: 0.92

Epoch 00011: f1 did not improve
Epoch 12/100
 - 7s - loss: 1.7239 - acc: 0.8643 - val_loss: 6.4036 - val_acc: 0.5391
 - f1: 0.51

Epoch 00012: f1 did not improve
Epoch 13/100
 - 7s - loss: 1.8384 - acc: 0.8592 - val_loss: 1.3273 - val_acc: 0.9101
 - f1: 0.94

Epoch 00013: f1 did not improve
testing fold 1
f1_score: 0.95
training fold 2
Train on 1372 samples, validate on 344 samples
Epoch 1/100
 - 7s - loss: 2.7412 - acc: 0.6983 - val_loss: 1.3352 - val_acc: 0.8314
 - f1: 0.89

Epoch 00001: f1 improved from -inf to 0.89095, saving model to log/1524912024/1524913527/weights_2.best.h5
Epoch 2/100
 - 7s - loss: 2.3022 - acc: 0.7711 - val_loss: 3.4643 - val_acc: 0.6483
 - f1: 0.64

Epoch 00002: f1 did not improve
Epoch 3/100
 - 7s - loss: 1.9109 - acc: 0.8149 - val_loss: 1.7744 - val_acc: 0.8140
 - f1: 0.86

Epoch 00003: f1 did not improve
Epoch 4/100
 - 7s - loss: 1.7922 - acc: 0.8302 - val_loss: 1.3040 - val_acc: 0.8924
 - f1: 0.93

Epoch 00004: f1 improved from 0.89095 to 0.93164, saving model to log/1524912024/1524913527/weights_2.best.h5
Epoch 5/100
 - 7s - loss: 1.7771 - acc: 0.8433 - val_loss: 1.1889 - val_acc: 0.8750
 - f1: 0.93

Epoch 00005: f1 did not improve
Epoch 6/100
 - 7s - loss: 1.5759 - acc: 0.8586 - val_loss: 1.4036 - val_acc: 0.8866
 - f1: 0.94

Epoch 00006: f1 improved from 0.93164 to 0.93780, saving model to log/1524912024/1524913527/weights_2.best.h5
Epoch 7/100
 - 7s - loss: 1.7728 - acc: 0.8397 - val_loss: 2.0672 - val_acc: 0.8110
 - f1: 0.84

Epoch 00007: f1 did not improve
Epoch 8/100
 - 7s - loss: 1.6476 - acc: 0.8615 - val_loss: 1.7199 - val_acc: 0.8808
 - f1: 0.92

Epoch 00008: f1 did not improve
Epoch 9/100
 - 7s - loss: 1.5423 - acc: 0.8681 - val_loss: 1.3597 - val_acc: 0.8866
 - f1: 0.94

Epoch 00009: f1 improved from 0.93780 to 0.93935, saving model to log/1524912024/1524913527/weights_2.best.h5
Epoch 10/100
 - 7s - loss: 1.5666 - acc: 0.8812 - val_loss: 1.7794 - val_acc: 0.8488
 - f1: 0.88

Epoch 00010: f1 did not improve
Epoch 11/100
 - 7s - loss: 1.5873 - acc: 0.8724 - val_loss: 2.6930 - val_acc: 0.8256
 - f1: 0.89

Epoch 00011: f1 did not improve
Epoch 12/100
 - 7s - loss: 1.7095 - acc: 0.8695 - val_loss: 1.2280 - val_acc: 0.9099
 - f1: 0.95

Epoch 00012: f1 improved from 0.93935 to 0.94799, saving model to log/1524912024/1524913527/weights_2.best.h5
Epoch 13/100
 - 7s - loss: 1.6225 - acc: 0.8768 - val_loss: 1.1691 - val_acc: 0.9041
 - f1: 0.94

Epoch 00013: f1 did not improve
Epoch 14/100
 - 7s - loss: 1.6977 - acc: 0.8724 - val_loss: 3.0197 - val_acc: 0.7733
 - f1: 0.82

Epoch 00014: f1 did not improve
Epoch 15/100
 - 7s - loss: 1.7200 - acc: 0.8673 - val_loss: 1.2279 - val_acc: 0.9070
 - f1: 0.94

Epoch 00015: f1 did not improve
Epoch 16/100
 - 7s - loss: 1.7473 - acc: 0.8681 - val_loss: 1.4098 - val_acc: 0.8866
 - f1: 0.94

Epoch 00016: f1 did not improve
Epoch 17/100
 - 7s - loss: 1.8199 - acc: 0.8644 - val_loss: 4.6007 - val_acc: 0.6105
 - f1: 0.71

Epoch 00017: f1 did not improve
testing fold 2
f1_score: 0.95
training fold 3
Train on 1373 samples, validate on 343 samples
Epoch 1/100
 - 7s - loss: 3.0187 - acc: 0.6715 - val_loss: 2.7795 - val_acc: 0.5831
 - f1: 0.68

Epoch 00001: f1 improved from -inf to 0.67513, saving model to log/1524912024/1524913527/weights_3.best.h5
Epoch 2/100
 - 7s - loss: 2.1962 - acc: 0.7786 - val_loss: 1.1195 - val_acc: 0.9096
 - f1: 0.94

Epoch 00002: f1 improved from 0.67513 to 0.93984, saving model to log/1524912024/1524913527/weights_3.best.h5
Epoch 3/100
 - 7s - loss: 1.9447 - acc: 0.8092 - val_loss: 1.2279 - val_acc: 0.8892
 - f1: 0.93

Epoch 00003: f1 did not improve
Epoch 4/100
 - 7s - loss: 1.9873 - acc: 0.8230 - val_loss: 2.1440 - val_acc: 0.7755
 - f1: 0.83

Epoch 00004: f1 did not improve
Epoch 5/100
 - 7s - loss: 1.6842 - acc: 0.8485 - val_loss: 1.9559 - val_acc: 0.8659
 - f1: 0.92

Epoch 00005: f1 did not improve
Epoch 6/100
 - 7s - loss: 1.6731 - acc: 0.8456 - val_loss: 1.3082 - val_acc: 0.9155
 - f1: 0.95

Epoch 00006: f1 improved from 0.93984 to 0.94834, saving model to log/1524912024/1524913527/weights_3.best.h5
Epoch 7/100
 - 7s - loss: 1.6423 - acc: 0.8551 - val_loss: 1.3299 - val_acc: 0.9067
 - f1: 0.94

Epoch 00007: f1 did not improve
Epoch 8/100
 - 7s - loss: 1.6432 - acc: 0.8653 - val_loss: 1.2442 - val_acc: 0.8980
 - f1: 0.93

Epoch 00008: f1 did not improve
Epoch 9/100
 - 7s - loss: 1.5410 - acc: 0.8602 - val_loss: 1.3511 - val_acc: 0.8980
 - f1: 0.93

Epoch 00009: f1 did not improve
Epoch 10/100
 - 7s - loss: 1.5870 - acc: 0.8645 - val_loss: 1.2448 - val_acc: 0.8950
 - f1: 0.94

Epoch 00010: f1 did not improve
Epoch 11/100
 - 7s - loss: 1.7771 - acc: 0.8594 - val_loss: 1.3385 - val_acc: 0.9038
 - f1: 0.94

Epoch 00011: f1 did not improve
testing fold 3
f1_score: 0.95
training fold 4
Train on 1374 samples, validate on 342 samples
Epoch 1/100
 - 7s - loss: 3.6325 - acc: 0.6376 - val_loss: 1.3013 - val_acc: 0.8304
 - f1: 0.88

Epoch 00001: f1 improved from -inf to 0.88047, saving model to log/1524912024/1524913527/weights_4.best.h5
Epoch 2/100
 - 7s - loss: 2.2411 - acc: 0.7889 - val_loss: 0.9798 - val_acc: 0.8918
 - f1: 0.93

Epoch 00002: f1 improved from 0.88047 to 0.93023, saving model to log/1524912024/1524913527/weights_4.best.h5
Epoch 3/100
 - 7s - loss: 2.0978 - acc: 0.8086 - val_loss: 1.3495 - val_acc: 0.8684
 - f1: 0.93

Epoch 00003: f1 did not improve
Epoch 4/100
 - 7s - loss: 1.9052 - acc: 0.8180 - val_loss: 1.5706 - val_acc: 0.8655
 - f1: 0.91

Epoch 00004: f1 did not improve
Epoch 5/100
 - 7s - loss: 1.9307 - acc: 0.8319 - val_loss: 1.0380 - val_acc: 0.9064
 - f1: 0.93

Epoch 00005: f1 improved from 0.93023 to 0.93191, saving model to log/1524912024/1524913527/weights_4.best.h5
Epoch 6/100
 - 7s - loss: 1.7452 - acc: 0.8479 - val_loss: 1.1024 - val_acc: 0.9035
 - f1: 0.93

Epoch 00006: f1 did not improve
Epoch 7/100
 - 7s - loss: 1.8222 - acc: 0.8428 - val_loss: 0.9576 - val_acc: 0.9240
 - f1: 0.95

Epoch 00007: f1 improved from 0.93191 to 0.95087, saving model to log/1524912024/1524913527/weights_4.best.h5
Epoch 8/100
 - 7s - loss: 1.7174 - acc: 0.8457 - val_loss: 0.8976 - val_acc: 0.9240
 - f1: 0.95

Epoch 00008: f1 improved from 0.95087 to 0.95099, saving model to log/1524912024/1524913527/weights_4.best.h5
Epoch 9/100
 - 7s - loss: 1.5386 - acc: 0.8690 - val_loss: 1.0567 - val_acc: 0.9181
 - f1: 0.95

Epoch 00009: f1 did not improve
Epoch 10/100
 - 7s - loss: 1.6605 - acc: 0.8559 - val_loss: 1.1195 - val_acc: 0.9035
 - f1: 0.92

Epoch 00010: f1 did not improve
Epoch 11/100
 - 7s - loss: 1.7177 - acc: 0.8603 - val_loss: 1.2803 - val_acc: 0.8947
 - f1: 0.93

Epoch 00011: f1 did not improve
Epoch 12/100
 - 7s - loss: 1.6983 - acc: 0.8617 - val_loss: 1.3565 - val_acc: 0.9006
 - f1: 0.93

Epoch 00012: f1 did not improve
Epoch 13/100
 - 7s - loss: 1.8563 - acc: 0.8530 - val_loss: 1.0894 - val_acc: 0.9064
 - f1: 0.94

Epoch 00013: f1 did not improve
testing fold 4
f1_score: 0.95
training fold 5
Train on 1374 samples, validate on 342 samples
Epoch 1/100
 - 7s - loss: 3.3121 - acc: 0.6703 - val_loss: 1.2165 - val_acc: 0.8860
 - f1: 0.92

Epoch 00001: f1 improved from -inf to 0.91675, saving model to log/1524912024/1524913527/weights_5.best.h5
Epoch 2/100
 - 7s - loss: 2.2200 - acc: 0.7817 - val_loss: 2.0094 - val_acc: 0.8012
 - f1: 0.85

Epoch 00002: f1 did not improve
Epoch 3/100
 - 7s - loss: 2.1048 - acc: 0.7969 - val_loss: 2.6136 - val_acc: 0.8304
 - f1: 0.90

Epoch 00003: f1 did not improve
Epoch 4/100
 - 7s - loss: 2.0093 - acc: 0.8210 - val_loss: 1.0915 - val_acc: 0.9269
 - f1: 0.95

Epoch 00004: f1 improved from 0.91675 to 0.94968, saving model to log/1524912024/1524913527/weights_5.best.h5
Epoch 5/100
 - 7s - loss: 1.8569 - acc: 0.8275 - val_loss: 1.1534 - val_acc: 0.9064
 - f1: 0.93

Epoch 00005: f1 did not improve
Epoch 6/100
 - 7s - loss: 1.8439 - acc: 0.8544 - val_loss: 1.1312 - val_acc: 0.9035
 - f1: 0.93

Epoch 00006: f1 did not improve
Epoch 7/100
 - 7s - loss: 1.6312 - acc: 0.8646 - val_loss: 1.0637 - val_acc: 0.9181
 - f1: 0.94

Epoch 00007: f1 did not improve
Epoch 8/100
 - 7s - loss: 1.7621 - acc: 0.8588 - val_loss: 1.2533 - val_acc: 0.9006
 - f1: 0.93

Epoch 00008: f1 did not improve
Epoch 9/100
 - 7s - loss: 1.6200 - acc: 0.8617 - val_loss: 1.7125 - val_acc: 0.8450
 - f1: 0.90

Epoch 00009: f1 did not improve
testing fold 5
f1_score: 0.95
model_config: {'attention_input': 2, 'lexical_feature': [1, 2, 3, 4], 'piecewise_max_pool': True}, f1_avg = 0.95
